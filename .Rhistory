rm(list=ls())
# install.packages("pastecs")
# install.packages('corrplot')
# install.packages("ROCR")
# install.packages("DescTools")
# install.packages("Hmisc")
# install.packages('visreg')
# install.packages('car')
# install.packages("caret")
## All libraries given to us in code snippets in case we need them
library(haven)
library(pastecs)
library(caret)
library(corrplot)
library(MASS)
library(visreg)
# library(brglm)
# library(ROCR)
# library(DescTools)
# library(Hmisc)
library(mgcv)
library(car)
library(tidyverse)
#setwd("C:\\Users\\Bill\\Documents\\NCSU\\Course Work\\Fall\\Logistic Regression\\Final Project")
#setwd("C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\Project\\")
setwd("C:\\Users\\Grant\\Documents\\MSA\\Fall\\Logistic Regression")
#path <- "C:\\Users\\Bill\\Documents\\NCSU\\Course Work\\Fall\\Logistic Regression\\Final Project\\"
#path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\data\\Logistic Data\\"
#path <- "C:\\Users\\gavin\\Desktop\\Logisitic_Regression_Data\\"
path <-("C:\\Users\\Grant\\Documents\\MSA\\Fall\\Logistic Regression\\")
input.file <- "construction.sas7bdat"
construction <- read_sas(paste(path, input.file,sep = ""))
############################################
########  CLEANING   #######################
############################################
#by S.Powell
# ADDING METRICS OF INTEREST
# of competitors
construction <- construction %>%
mutate(comp.count = select(., Competitor_A:Competitor_J) %>% apply(1, sum, na.rm=TRUE)) %>%
mutate(profit = Bid_Price__Millions_ - Estimated_Cost__Millions_) %>%
mutate(perc_over_bid = (Bid_Price__Millions_ - Winning_Bid_Price__Millions_)/Winning_Bid_Price__Millions_) %>%
mutate(Win = as.numeric(as.factor(Win_Bid))-1) #converts to factor levels 1 and 2 then subtracts 1 for binary
#needed 0,1 for regression modelling later
#setwd("C:\\Users\\Bill\\Documents\\NCSU\\Course Work\\Fall\\Logistic Regression\\Final Project")
setwd("C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\Project\\")
#setwd("C:\\Users\\Grant\\Documents\\MSA\\Fall\\Logistic Regression")
#path <- "C:\\Users\\Bill\\Documents\\NCSU\\Course Work\\Fall\\Logistic Regression\\Final Project\\"
path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\data\\Logistic Data\\"
#path <- "C:\\Users\\gavin\\Desktop\\Logisitic_Regression_Data\\"
#path <-("C:\\Users\\Grant\\Documents\\MSA\\Fall\\Logistic Regression\\")
input.file <- "construction.sas7bdat"
construction <- read_sas(paste(path, input.file,sep = ""))
############################################
########  CLEANING   #######################
############################################
#by S.Powell
# ADDING METRICS OF INTEREST
# of competitors
construction <- construction %>%
mutate(comp.count = select(., Competitor_A:Competitor_J) %>% apply(1, sum, na.rm=TRUE)) %>%
mutate(profit = Bid_Price__Millions_ - Estimated_Cost__Millions_) %>%
mutate(perc_over_bid = (Bid_Price__Millions_ - Winning_Bid_Price__Millions_)/Winning_Bid_Price__Millions_) %>%
mutate(Win = as.numeric(as.factor(Win_Bid))-1) #converts to factor levels 1 and 2 then subtracts 1 for binary
View(construction)
Sec.names <- c("Transportation",
"Lodging",
"Multi-family residential",
"Amusement/recreation",
"Highway/street",
"Education",
"Healthcare",
"Manufacturing",
"Power",
"Military") #assumed order based on PDF. No actual key provided
Sector <- as.character(c(1:10))
sector.names <- as.data.frame(cbind(Sector, Sec.names))
construction$Sector <- as.character(construction$Sector)
construction <- left_join(construction, sector.names, by="Sector")
construction <- construction[,c(1:4,24,5:23)] #reordering to check merge success
#DIVIDE INTO TRAINING / VALIDATION SETS
set.seed(123)
train_ind <- createDataPartition(construction$Estimated_Cost__Millions_, p=0.70, list=FALSE)
help("createDataPartition")
ctrain <<- construction[train_ind,]
cval <- construction[-train_ind,]
#DIVIDE TRAINIG INTO CONTINUOUS, CATEGORICAL
continuous <- c(
"Estimated_Cost__Millions_",
"Estimated_Years_to_Complete",
"Bid_Price__Millions_",
"Number_of_Competitor_Bids",
"Winning_Bid_Price__Millions_",
"Cost_After_Engineering_Estimate_",
"profit",
"perc_over_bid",
"comp.count")
ctrain_cont <- select(ctrain, continuous)
ctrain_cat <- select(ctrain, -continuous)
ctrain_cat <- as.data.frame(sapply(ctrain_cat, as.character)) #converting binary dbls to factors
ctrain_cont2 <- select(ctrain_cont, -c("Estimated_Cost__Millions_", "Winning_Bid_Price__Millions_")) #reduced to get rid of some redundant variables
View(construction)
View(ctrain_cont)
View(ctrain_cat)
str(ctrain)
ctrain_cat <- select(ctrain, -continuous)
ctrain_cat <- dplyr::select(ctrain, -continuous)
ctrain_cat <- dplyr::select(ctrain, (-continuous))
what <- ctrain[, -'profit']
what <- ctrain[, -c('profit')]
what <- ctrain[, 'profit']
testerosa <- dplyr::select(ctrain, setdiff(colnames(ctrain, continuous)))
setdiff(colnames(ctrain, continuous))
setdiff(colnames(ctrain), continuous)
testerosa <- dplyr::select(ctrain, setdiff(colnames(ctrain), continuous))
testerosa
# install.packages("brglm") #necessary for bias reduction, penalized likelihood
library(haven) #necessary for import of SAS
library(tidyverse) # necessary for life in R
# library(brglm)
rm(list=ls()) # for cleaning global environment, to guarantee a clean slate
# import the file
# PLEASE just add a new variable for your file path
sp_path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\data\\Logistic Data"
gf_path <- "C:\\Users\\Grant\\Downloads\\MSA2019LogisticData\\data"
path <- sp_path #CHANGE THIS
setwd(file.path(path))
file <- paste(path, "\\insurance_t.sas7bdat",sep='')
insurance_t <- read_sas(file)
#head(insurance_t)
#str(insurance_t)
# TODO set alpha, or ensure we know what alpha we're using
#quick fit of Powell variables
fit_sp <- glm(INS ~
INCOME + HMOWN + LORES + HMVAL + AGE + CRSCORE + MOVED + INAREA + RES,
data = insurance_t, family = binomial(link = "logit"))
summary(fit_sp)
# RECOMMENDED VARS
#WJ 1-9 recommended vars : DDA + DDABAL
#MR 10-18 recommended vars : NSFAMT	+ PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT + POSAMT
#GF 19-27 recommended vars : CD + INV + IRA + CDBAL + IRABAL
#GW 28-38 recommended vars : ILSBAL + MM + MTG + CC + SDB
#SP 38-47 almost all vars : INCOME + HMOWN + LORES + HMVAL + AGE + CRSCORE + MOVED + INAREA + INS + BRANCH + RES
insurance.sel <- select(insurance_t,
DDA, DDABAL,
NSFAMT, PHONE, TELLER,	SAV,	SAVBAL, ATMAMT, POSAMT,
CD, INV, IRA, CDBAL, IRABAL,
ILSBAL, MM, MTG, CC, SDB,
INCOME, HMVAL, INAREA,
INS)
insurance.sel2 <- select(insurance_t,
DDA, DDABAL,
PHONE, TELLER,	SAV,	SAVBAL, ATMAMT,
CD, INV, IRA, CDBAL,
MM, MTG, CC,
INS)
#Filtering into two groups to possible identify source of missing
insurance_t.missing <- insurance_t %>%
mutate(missing_group = is.na(PHONE)) %>%
filter(missing_group==TRUE)
insurance_t.complete <- insurance_t %>%
mutate(missing_group = is.na(PHONE)) %>%
filter(missing_group==FALSE)
#comparing summaries of individual variables (large differences would indicate source of missing)
summary(insurance_t.complete$ACCTAGE) - summary(insurance_t.missing$ACCTAGE)
summary(insurance_t.complete$HMVAL) - summary(insurance_t.missing$HMVAL)
summary(insurance_t.complete$LORES) - summary(insurance_t.missing$LORES)
summary(insurance_t.complete$INAREA) - summary(insurance_t.missing$INAREA)
summary(insurance_t.complete$MOVED) - summary(insurance_t.missing$MOVED)
summary(insurance_t.complete$AGE) - summary(insurance_t.missing$AGE)
table(insurance_t.complete$BRANCH)
table(insurance_t.missing$BRANCH) #BRANCH matches the problem
#missing value summary worthy of finalization
insurance.branch <- insurance_t %>%
group_by(BRANCH) %>%
summarize(Count=n(),
PHONE.mean=mean(PHONE, na.rm=TRUE),
PHONE.sum=sum(PHONE, na.rm=TRUE),
PHONE.NA=sum(is.na(PHONE)),
CC.NA=sum(is.na(CC)),
CC.TRUE=sum(INV==1),
CC.FALSE=sum(INV==0),
INV.NA=sum(is.na(INV)),
INV.TRUE=sum(INV==1),
INV.FALSE=sum(INV==0)
)
View(insurance.branch)
write.csv(insurance.branch, file="insurance_branch.csv")
# Cleaning datasets for easier use and comparison
insurance.na.omit <- na.omit(insurance_t) #if we want datasets without 'missingness'
insurance.sel.na.omit <- na.omit(insurance.sel) #if we want datasets without 'missingness'
# ITERATION 1
#Building model from all variables that were recommended from data-exploration
fit1 <- glm(INS ~ DDA + DDABAL +
NSFAMT	+ PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT + POSAMT +
CD + INV + IRA + CDBAL + IRABAL+
ILSBAL + MM + MTG + CC + SDB +
INCOME + HMVAL + INAREA,
data = insurance.sel, family = binomial(link = "logit"))
summary(fit1)
#ITERATION 2: manual reduction of variables
fit2 <- glm(INS ~ DDA + DDABAL +
PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT +
CD + INV + IRA + CDBAL +
MM + MTG + CC,
data = insurance.sel, family = binomial(link = "logit"))
summary(fit2)
#save(fit2, "LogisticsHW1.RData")
# install.packages("brglm") #necessary for bias reduction, penalized likelihood
library(haven) #necessary for import of SAS
library(tidyverse) # necessary for life in R
# library(brglm)
rm(list=ls()) # for cleaning global environment, to guarantee a clean slate
# import the file
# PLEASE just add a new variable for your file path
sp_path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\data\\Logistic Data"
gf_path <- "C:\\Users\\Grant\\Downloads\\MSA2019LogisticData\\data"
path <- sp_path #CHANGE THIS TO YOURS
setwd(file.path(path))
file <- paste(path, "\\insurance_t.sas7bdat",sep='')
insurance_t <- read_sas(file)
#head(insurance_t)
#str(insurance_t)
# TODO set alpha, or ensure we know what alpha we're using
#quick fit of Powell variables
fit_sp <- glm(INS ~
INCOME + HMOWN + LORES + HMVAL + AGE + CRSCORE + MOVED + INAREA + RES,
data = insurance_t, family = binomial(link = "logit"))
summary(fit_sp)
# RECOMMENDED VARS
#WJ 1-9 recommended vars : DDA + DDABAL
#MR 10-18 recommended vars : NSFAMT	+ PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT + POSAMT
#GF 19-27 recommended vars : CD + INV + IRA + CDBAL + IRABAL
#GW 28-38 recommended vars : ILSBAL + MM + MTG + CC + SDB
#SP 38-47 almost all vars : INCOME + HMOWN + LORES + HMVAL + AGE + CRSCORE + MOVED + INAREA + INS + BRANCH + RES
insurance.sel <- select(insurance_t,
DDA, DDABAL,
NSFAMT, PHONE, TELLER,	SAV,	SAVBAL, ATMAMT, POSAMT,
CD, INV, IRA, CDBAL, IRABAL,
ILSBAL, MM, MTG, CC, SDB,
INCOME, HMVAL, INAREA,
INS)
insurance.sel2 <- select(insurance_t,
DDA, DDABAL,
PHONE, TELLER,	SAV,	SAVBAL, ATMAMT,
CD, INV, IRA, CDBAL,
MM, MTG, CC,
INS)
#Filtering into two groups to possible identify source of missing
insurance_t.missing <- insurance_t %>%
mutate(missing_group = is.na(PHONE)) %>%
filter(missing_group==TRUE)
insurance_t.complete <- insurance_t %>%
mutate(missing_group = is.na(PHONE)) %>%
filter(missing_group==FALSE)
#comparing summaries of individual variables (large differences would indicate source of missing)
summary(insurance_t.complete$ACCTAGE) - summary(insurance_t.missing$ACCTAGE)
summary(insurance_t.complete$HMVAL) - summary(insurance_t.missing$HMVAL)
summary(insurance_t.complete$LORES) - summary(insurance_t.missing$LORES)
summary(insurance_t.complete$INAREA) - summary(insurance_t.missing$INAREA)
summary(insurance_t.complete$MOVED) - summary(insurance_t.missing$MOVED)
summary(insurance_t.complete$AGE) - summary(insurance_t.missing$AGE)
table(insurance_t.complete$BRANCH)
table(insurance_t.missing$BRANCH) #BRANCH matches the problem
#missing value summary worthy of finalization
insurance.branch <- insurance_t %>%
group_by(BRANCH) %>%
summarize(Count=n(),
PHONE.mean=mean(PHONE, na.rm=TRUE),
PHONE.sum=sum(PHONE, na.rm=TRUE),
PHONE.NA=sum(is.na(PHONE)),
CC.NA=sum(is.na(CC)),
CC.TRUE=sum(INV==1),
CC.FALSE=sum(INV==0),
INV.NA=sum(is.na(INV)),
INV.TRUE=sum(INV==1),
INV.FALSE=sum(INV==0)
)
write.csv(insurance.branch, file="insurance_branch.csv")
# Cleaning datasets for easier use and comparison
insurance.na.omit <- na.omit(insurance_t) #if we want datasets without 'missingness'
insurance.sel.na.omit <- na.omit(insurance.sel) #if we want datasets without 'missingness'
# ITERATION 1
#Building model from all variables that were recommended from data-exploration
fit1 <- glm(INS ~ DDA + DDABAL +
NSFAMT	+ PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT + POSAMT +
CD + INV + IRA + CDBAL + IRABAL+
ILSBAL + MM + MTG + CC + SDB +
INCOME + HMVAL + INAREA,
data = insurance.sel, family = binomial(link = "logit"))
summary(fit1)
#ITERATION 2: manual reduction of variables
fit2 <- glm(INS ~ DDA + DDABAL +
PHONE	+ TELLER +	SAV +	SAVBAL + ATMAMT +
CD + INV + IRA + CDBAL +
MM + MTG + CC,
data = insurance.sel, family = binomial(link = "logit"))
summary(fit2)
save(fit2, insurance_t, "LogisticsHW1.RData")
"
sp_path2 <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance"
sp_path2 <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance"
sp_savepath <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance"
setwd("C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance")
save(fit2, insurance_t, "LogisticsHW1.RData")
save(fit2, insurance_t, file="LogisticsHW1.RData")
library(haven) #necessary for import of SAS
library(tidyverse) # necessary for life in R
# library(brglm)
rm(list=ls()) # for cleaning global environment, to guarantee a clean slate
file.path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance\\LogisticsHW1.RData"
load(file.path)
############################################
#################  Results  ################
############################################
#By S.Powell
library(haven) #necessary for import of SAS
library(tidyverse) # necessary for life in R
# library(brglm)
rm(list=ls()) # for cleaning global environment, to guarantee a clean slate
sp_path <- "C:\\Users\\Steven\\Documents\\MSA\\Analytics Foundations\\lab and hw\\Logistic\\logistic-insurance\\LogisticsHW1.RData"
gf_path <- "C:\\Users\\Grant\\Downloads\\MSA2019LogisticData\\data"
wj_path <- "C:\\Users\\Bill\\Documents\\NCSU\\Course Work\\Fall\\Logistic Regression\\Final Project\\"
gw_path <- "C:\\Users\\gavin\\Desktop\\Logisitic_Regression_Data\\"
mr_path <- "C:\\Users\\molly\\"
load(sp_path)
############################################
#################  Results  ################
############################################
#By S.Powell
